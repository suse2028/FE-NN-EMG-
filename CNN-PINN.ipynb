{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe4d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import scipy\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import butter, lfilter\n",
    "from scipy.fft import fft, ifft, fftfreq\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71ac0d1",
   "metadata": {},
   "source": [
    "Relevant importations: Preprocessing functions have their basis in scipy, and model architechture is done in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_uci_lower_limb_dataset(save_dir='./data'):\n",
    "    \"\"\"\n",
    "    Download the UCI Lower Limb Movement Dataset\n",
    "    \"\"\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00526/LowerLimbMovements.zip\"\n",
    "    \n",
    "    if not os.path.exists(os.path.join(save_dir, 'LowerLimbMovements')):\n",
    "        print(\"Downloading UCI Lower Limb EMG dataset...\")\n",
    "        r = requests.get(url)\n",
    "        z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "        z.extractall(save_dir)\n",
    "        print(\"Dataset downloaded and extracted successfully!\")\n",
    "    else:\n",
    "        print(\"UCI Lower Limb EMG dataset already exists.\")\n",
    "    \n",
    "    return os.path.join(save_dir, 'LowerLimbMovements')\n",
    "\n",
    "\n",
    "def process_uci_lower_limb_dataset(data_dir, output_file='lower_limb_emg_gait_data.csv'):\n",
    "    \"\"\"\n",
    "    Process the UCI Lower Limb Movement Dataset and extract gait-related data\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    print(f\"Processing data from directory: {data_dir}\")\n",
    "    \n",
    "    # The dataset contains multiple subjects with files like 'subject1.csv', 'subject2.csv', etc.\n",
    "    subject_files = [f for f in os.listdir(data_dir) if f.startswith('subject') and f.endswith('.csv')]\n",
    "    \n",
    "    for subject_file in subject_files:\n",
    "        try:\n",
    "            file_path = os.path.join(data_dir, subject_file)\n",
    "            print(f\"Processing file: {subject_file}\")\n",
    "            \n",
    "            # Read the subject's data\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Extract EMG columns\n",
    "            emg_cols = [col for col in df.columns if col.startswith('emg')]\n",
    "            \n",
    "            # Extract joint angle columns\n",
    "            angle_cols = ['ankle', 'knee', 'hip']\n",
    "            \n",
    "            # Check if required columns exist\n",
    "            if not all(col in df.columns for col in emg_cols + angle_cols):\n",
    "                print(f\"Skipping {subject_file}: missing required columns\")\n",
    "                continue\n",
    "                \n",
    "            # Add subject identifier and extract needed columns\n",
    "            df_subset = df[emg_cols + angle_cols].copy()\n",
    "            df_subset['subject_id'] = int(subject_file.replace('subject', '').replace('.csv', ''))\n",
    "            \n",
    "            # Append to our collection\n",
    "            all_data.append(df_subset)\n",
    "            print(f\"Added data from {subject_file}: {len(df_subset)} samples\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {subject_file}: {e}\")\n",
    "    \n",
    "    if len(all_data) > 0:\n",
    "        # Combine all subject data\n",
    "        df_combined = pd.concat(all_data, ignore_index=True)\n",
    "        \n",
    "        # Save the processed data\n",
    "        df_combined.to_csv(output_file, index=False)\n",
    "        print(f\"Combined dataset saved to {output_file} with {len(df_combined)} samples\")\n",
    "        \n",
    "        return output_file\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_data(file):\n",
    "    \"\"\"\n",
    "    Load the processed Lower Limb EMG dataset\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(file)\n",
    "    \n",
    "    # Extract EMG signals\n",
    "    emg_columns = [col for col in data.columns if col.startswith('emg')]\n",
    "    emg_signals = data[emg_columns].values.T\n",
    "    \n",
    "    # Extract joint angles (ankle, knee, hip)\n",
    "    angle_columns = ['ankle', 'knee']  # Using ankle and knee as targets\n",
    "    labels = data[angle_columns].values\n",
    "    \n",
    "    return emg_signals, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e83e79",
   "metadata": {},
   "source": [
    "Dataset  to be used: UCI EMG Dataset Lower Limb. This dataset samples subjects in a controlled or predictable motion setting (walking, standing). This element of periodicity (or null case with standing/sitting) is necessary for a good prediction accuracy and established of the boundary conditions around motion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a73abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Badnapss filter (restricted signal between 20-450 mV, most of legitimate EMG signal)\n",
    "def bandpass_filter(signal_data, crit_freq=[20, 450], sampling_freq=125, plot=False, channel=0):\n",
    "    order = 4\n",
    "    b, a = scipy.signal.butter(order, crit_freq, btype='bandpass', fs=sampling_freq)\n",
    "    processed_signal = scipy.signal.filtfilt(b, a, signal_data)\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel(f'Normalized amplitude of channel {channel}')\n",
    "        plt.title(f'{crit_freq[0]}-{crit_freq[1]}Hz bandpass filter')\n",
    "\n",
    "        signal_min = np.min(signal_data, axis=1, keepdims=True)\n",
    "        signal_max = np.max(signal_data, axis=1, keepdims=True)\n",
    "        normed_signal = (signal_data - signal_min) / (signal_max - signal_min)\n",
    "\n",
    "        filtered_min = np.min(processed_signal, axis=1, keepdims=True)\n",
    "        filtered_max = np.max(processed_signal, axis=1, keepdims=True)\n",
    "        normed_filt = (processed_signal - filtered_min) / (filtered_max - filtered_min)\n",
    "\n",
    "        plt.plot(np.arange(normed_signal[channel].size), normed_signal[channel], label='Input')\n",
    "        plt.plot(np.arange(normed_filt[channel].size), normed_filt[channel], label='Transformed')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return processed_signal\n",
    "\n",
    "#Notch filter to eliminate common sources of artifacts from electronics (50-60 mV)\n",
    "def notch_filter(signal_data, notch_freqs=[50, 60], Q=30, sampling_freq=125):\n",
    "    filtered_signal = signal_data.copy()\n",
    "\n",
    "    for f0 in notch_freqs:\n",
    "        b, a = signal.iirnotch(f0, Q, fs=sampling_freq)\n",
    "        filtered_signal = signal.filtfilt(b, a, filtered_signal)\n",
    "\n",
    "    return filtered_signal\n",
    "\n",
    "#Getting the absolute value of the data -> interest lies mainly in signal magnitude\n",
    "def rectify(signal_data):\n",
    "    return np.abs(signal_data)\n",
    "\n",
    "#FFT Filter: Given that any sharp signal deviation does not also occur periodically, eliminate it from the spectrum\n",
    "#Justification: We assume that the provided gait data is periodic, \n",
    "def fft_analysis_and_filter(signal_data, sampling_freq=125, gait_freq_range=[0.5, 2.5], plot=False, channel=0):\n",
    "    n_samples = signal_data.shape[1]\n",
    "    n_channels = signal_data.shape[0]\n",
    "\n",
    "    fft_result = fft(signal_data)\n",
    "    freqs = fftfreq(n_samples, 1 / sampling_freq)\n",
    "\n",
    "    mask = np.zeros((n_channels, n_samples), dtype=bool)\n",
    "    for i in range(n_channels):\n",
    "        mask[i] = (np.abs(freqs) < 0.1) | (\n",
    "                    (np.abs(freqs) >= gait_freq_range[0]) & (np.abs(freqs) <= gait_freq_range[1]))\n",
    "\n",
    "        for harmonic in range(2, 6):\n",
    "            mask[i] |= ((np.abs(freqs) >= harmonic * gait_freq_range[0]) &\n",
    "                        (np.abs(freqs) <= harmonic * gait_freq_range[1]))\n",
    "\n",
    "    filtered_fft = fft_result.copy()\n",
    "    for i in range(n_channels):\n",
    "        filtered_fft[i, ~mask[i]] = 0\n",
    "\n",
    "    filtered_signal = np.real(ifft(filtered_fft))\n",
    "\n",
    "    if plot and channel < n_channels:\n",
    "        plt.figure(figsize=(15, 10))\n",
    "\n",
    "        plt.subplot(3, 1, 1)\n",
    "        plt.title(f'Original EMG Signal - Channel {channel}')\n",
    "        plt.plot(signal_data[channel]) \n",
    "        plt.xlabel('Sample')\n",
    "        plt.ylabel('Amplitude')\n",
    "\n",
    "        plt.subplot(3, 1, 2)\n",
    "        plt.title(f'Frequency Components - Channel {channel}')\n",
    "        pos_mask = freqs > 0\n",
    "        pos_freqs = freqs[pos_mask][:int(n_samples / 2)]\n",
    "        plt.plot(pos_freqs, 2.0 / n_samples * np.abs(fft_result[channel, pos_mask][:int(n_samples / 2)]))\n",
    "        plt.axvspan(gait_freq_range[0], gait_freq_range[1], alpha=0.3, color='green', label='Gait Freq Range')\n",
    "        plt.xlabel('Frequency (Hz)')\n",
    "        plt.ylabel('Magnitude')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(3, 1, 3)\n",
    "        plt.title(f'Filtered EMG Signal - Channel {channel}')\n",
    "        plt.plot(filtered_signal[channel])\n",
    "        plt.xlabel('Sample')\n",
    "        plt.ylabel('Amplitude')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return filtered_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdd8001",
   "metadata": {},
   "source": [
    "Preprocessing functions:\n",
    "- 1. Bandpass filter: EMG range restricted between 20-450 mV (with <20 commonly being a motion artifact, and >450 being too high of a voltage for any muscle condition)\n",
    "- 2. Notch Filter: Range further restricted by eliminating 50-60 mV (common source of artifacts from electronics)\n",
    "- 3. Signal Rectification: Taking the absolute value of the EMG spectrum, as magnitude is the more important factor in identifying the exact boundary conditions of the surrounding anatomical structures\n",
    "- 4. FFT Filter: We assume an element of periodicity within gait, and given the rectification performed, the magnitude of the EMG spectrum will reflect as such. This function checks for any spikes in the spectrum that are non-periodic and eliminate, coverting back to the time domain after operating in the frequency domain to filter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf57b7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(signal_data, sampling_freq=125, window_size=1, window_shift=0.016):\n",
    "    w_size = int(sampling_freq * window_size)\n",
    "    w_shift = int(sampling_freq * window_shift)\n",
    "\n",
    "    segments = []\n",
    "    i = 0\n",
    "    while i + w_size <= signal_data.shape[1]:\n",
    "        segments.append(signal_data[:, i:i + w_size])\n",
    "        i += w_shift\n",
    "\n",
    "    return segments\n",
    "\n",
    "\n",
    "def channel_rearrangement(signal_data, channel_order):\n",
    "    channel_order = [channel - 1 for channel in channel_order]\n",
    "    reindexed = np.zeros_like(signal_data)\n",
    "    for i, ind in enumerate(channel_order):\n",
    "        reindexed[i] = signal_data[ind]\n",
    "    return reindexed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01707575",
   "metadata": {},
   "source": [
    "Next, we divide the processed spectrum into windows, filling an initialized list (segments) with them. This is done to prepare the data as an iterable for the ML portion of the program. Then the channels are rearranged according to how the UCI dataset presents them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab69da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(file_path, ordered_channels, test_size=0.25):\n",
    "    emg_data, labels = get_data(file_path)\n",
    "\n",
    "    if ordered_channels:\n",
    "        emg_data = channel_rearrangement(emg_data, ordered_channels)\n",
    "\n",
    "    filtered_emg = bandpass_filter(emg_data, [20, 450], 125)\n",
    "    notched_emg = notch_filter(filtered_emg, [50, 60], 30, 125)\n",
    "    rectified_emg = rectify(notched_emg)\n",
    "    clean_emg = fft_analysis_and_filter(rectified_emg, 125, [0.5, 2.5])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        clean_emg.T,\n",
    "        labels,\n",
    "        test_size=test_size,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_val, X_test = X_test[:len(X_test) // 2], X_test[len(X_test) // 2:]\n",
    "    y_val, y_test = y_test[:len(y_test) // 2], y_test[len(y_test) // 2:]\n",
    "\n",
    "    X_train, X_val, X_test = X_train.T, X_val.T, X_test.T\n",
    "\n",
    "    train_emg = []\n",
    "    train_labels = []\n",
    "    valid_emg = []\n",
    "    valid_labels = []\n",
    "    test_emg = []\n",
    "    test_labels = []\n",
    "\n",
    "    train_segments = segmentation(X_train, 125, window_size=1.5, window_shift=0.0175)\n",
    "    train_emg.extend(train_segments)\n",
    "    train_labels.extend([y_train[0]] * len(train_segments))\n",
    "\n",
    "    val_segments = segmentation(X_val, 125, window_size=1.5, window_shift=0.0175)\n",
    "    valid_emg.extend(val_segments)\n",
    "    valid_labels.extend([y_val[0]] * len(val_segments))\n",
    "\n",
    "    test_segments = segmentation(X_test, 125, window_size=1.5, window_shift=0.0175)\n",
    "    test_emg.extend(test_segments)\n",
    "    test_labels.extend([y_test[0]] * len(test_segments))\n",
    "\n",
    "    return (\n",
    "        np.array(train_emg), np.array(train_labels),\n",
    "        np.array(valid_emg), np.array(valid_labels),\n",
    "        np.array(test_emg), np.array(test_labels)\n",
    "    )\n",
    "\n",
    "\n",
    "class EMGDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.features[idx]\n",
    "        y = self.labels[idx]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c9a310",
   "metadata": {},
   "source": [
    "Establish train-test splits and use Pytorch's CustomDataset construct (called later in the main function for program execution) for dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90651dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNRegression(nn.Module):\n",
    "    def __init__(self, input_channels, seq_length):\n",
    "        super(CNNRegression, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(64, 32, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(32, 16, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool1d(2)\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "\n",
    "        self.flat_features = 16 * (seq_length // 8)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.flat_features, 64)\n",
    "        self.dropout4 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x, t=None):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        x = x.view(-1, self.flat_features)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout4(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        output = self.fc3(x)\n",
    "\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1ae672",
   "metadata": {},
   "source": [
    "CNN Structure:\n",
    "    \n",
    "Justification: Sliding a convolution across the EMG spectrum input allows for the network to recognize patterns in the data, already augmented by the periodic nature of the dataset. For the establishment of numerical boundary conditions, pairing periodicity with the numerial output of a convolution will be very helpful. \n",
    "\n",
    "Structure: Compose the main body of Convolutional Layers as well as MaxPool and Dropout to prevent placebo patterns from arising. Finally, pass the transformed input across a few Linear Layers to flatten dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6a249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def physics_loss(pred, x, t, w=4.0, z=3.0):\n",
    "    dtheta_dt = torch.autograd.grad(\n",
    "        outputs=pred,\n",
    "        inputs=t,\n",
    "        grad_outputs=torch.ones_like(pred),\n",
    "        create_graph=True\n",
    "    )[0]\n",
    "\n",
    "    d2theta_dt2 = torch.autograd.grad(\n",
    "        outputs=dtheta_dt,\n",
    "        inputs=t,\n",
    "        grad_outputs=torch.ones_like(dtheta_dt),\n",
    "        create_graph=True\n",
    "    )[0]\n",
    "\n",
    "    residual = d2theta_dt2 + w * dtheta_dt + z * pred\n",
    "    phys_loss = torch.mean(residual ** 2)\n",
    "\n",
    "    return phys_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb3b2de",
   "metadata": {},
   "source": [
    "Physics-based loss: This forms the basis for the anatomical constraint of the model. Several key anatomical structures, including joints during gait, can be modeled with damper-driven oscillation. As such, this was the ODE used (represented in residual) to append to the typical MSE loss accrued during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f8428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn_model(model, train_loader, valid_loader, optimizer, num_epochs=100, device='cpu'):\n",
    "    print(\"Starting CNN model training...\")\n",
    "    model.to(device)\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        data_loss_total = 0.0\n",
    "        phys_loss_total = 0.0\n",
    "\n",
    "        for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            batch_size, channels, seq_len = x_batch.shape\n",
    "            dt = 0.001\n",
    "            t = torch.linspace(0, dt * (seq_len - 1), seq_len, device=device).view(1, -1, 1)\n",
    "            t = t.repeat(batch_size, 1, 1).requires_grad_(True)\n",
    "\n",
    "            x_batch.requires_grad_(True)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(x_batch, t)\n",
    "\n",
    "            data_loss = F.mse_loss(pred, y_batch)\n",
    "            phys_loss = physics_loss(pred, x_batch, t)\n",
    "            total_loss = data_loss + 0.1 * phys_loss\n",
    "\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += total_loss.item()\n",
    "            data_loss_total += data_loss.item()\n",
    "            phys_loss_total += phys_loss.item()\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"  Batch {batch_idx}/{len(train_loader)}, \"\n",
    "                      f\"Loss: {total_loss.item():.4f}, \"\n",
    "                      f\"Data Loss: {data_loss.item():.4f}, \"\n",
    "                      f\"Physics Loss: {phys_loss.item():.4f}\")\n",
    "            \n",
    "        model.eval()\n",
    "        valid_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in valid_loader:\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "\n",
    "                pred = model(x_batch)\n",
    "                loss = F.mse_loss(pred, y_batch)\n",
    "                valid_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_data_loss = data_loss_total / len(train_loader)\n",
    "        avg_phys_loss = phys_loss_total / len(train_loader)\n",
    "        avg_valid_loss = valid_loss / len(valid_loader)\n",
    "\n",
    "        train_losses.append(avg_train_loss)\n",
    "        valid_losses.append(avg_valid_loss)\n",
    "\n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} completed in {epoch_time:.2f} seconds.\")\n",
    "        print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
    "        print(f\"  Data Loss: {avg_data_loss:.4f}\")\n",
    "        print(f\"  Physics Loss: {avg_phys_loss:.4f}\")\n",
    "        print(f\"  Validation Loss: {avg_valid_loss:.4f}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(valid_losses, label='Validation Loss')\n",
    "    plt.title('Loss Over Time')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return model\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6bd0d2",
   "metadata": {},
   "source": [
    "Model training - physics loss is combined with data loss in gradient descent to optimally align the returned boundary condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f065ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "  def evaluate_model(model, test_loader, device='cpu', boundary_model=None, is_lstm=False):\n",
    "    print(\"Evaluating model on test data...\")\n",
    "    model.eval()\n",
    "    if boundary_model:\n",
    "        boundary_model.eval()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            if is_lstm and boundary_model:\n",
    "                boundary_cond = boundary_model(x_batch)\n",
    "                pred = model(x_batch, boundary_cond)\n",
    "            else:\n",
    "                pred = model(x_batch)\n",
    "\n",
    "            loss = F.mse_loss(pred, y_batch)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            predictions.extend(pred.cpu().numpy())\n",
    "            labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "\n",
    "    predictions = np.array(predictions)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    if predictions.shape[1] == 2:\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.scatter(labels[:, 0], predictions[:, 0], alpha=0.5)\n",
    "        plt.plot([min(labels[:, 0]), max(labels[:, 0])], [min(labels[:, 0]), max(labels[:, 0])], 'r--')\n",
    "        plt.xlabel('Actual Angle')\n",
    "        plt.ylabel('Predicted Angle')\n",
    "        plt.title('Angle Predictions')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.scatter(labels[:, 1], predictions[:, 1], alpha=0.5)\n",
    "        plt.plot([min(labels[:, 1]), max(labels[:, 1])], [min(labels[:, 1]), max(labels[:, 1])], 'r--')\n",
    "        plt.xlabel('Actual Position')\n",
    "        plt.ylabel('Predicted Position')\n",
    "        plt.title('Position Predictions')\n",
    "    else:\n",
    "        plt.scatter(labels, predictions, alpha=0.5)\n",
    "        plt.plot([min(labels), max(labels)], [min(labels), max(labels)], 'r--')\n",
    "        plt.xlabel('Actual Values')\n",
    "        plt.ylabel('Predicted Values')\n",
    "        plt.title('Predictions vs labels')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return avg_test_loss, predictions, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad31def0",
   "metadata": {},
   "source": [
    "Model evaluation using test set data previously designated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c293b752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(emg_data_file, ordered_channels=None):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "       \n",
    "        train_emg, train_labels, valid_emg, valid_labels, test_emg, test_labels = prepare_dataset(\n",
    "        emg_data_file, ordered_channels\n",
    "    )\n",
    "\n",
    "    input_channels = train_emg.shape[1]\n",
    "    seq_length = train_emg.shape[2]\n",
    "\n",
    "    train_dataset = EMGDataset(train_emg, train_labels)\n",
    "    valid_dataset = EMGDataset(valid_emg, valid_labels)\n",
    "    test_dataset = EMGDataset(test_emg, test_labels)\n",
    "\n",
    "    batch_size = 32\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    cnn_model = CNNRegression(input_channels, seq_length).to(device)\n",
    "    cnn_optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "\n",
    "    trained_cnn = train_cnn_model(\n",
    "        cnn_model,\n",
    "        train_loader,\n",
    "        valid_loader,\n",
    "        cnn_optimizer,\n",
    "        num_epochs=50,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    cnn_test_loss, cnn_predictions, cnn_labels = evaluate_model(\n",
    "        trained_cnn,\n",
    "        test_loader,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    torch.save(trained_cnn.state_dict(), 'cnn_boundary_model.pth')\n",
    "\n",
    "    return trained_cnn, cnn_test_loss, cnn_predictions, cnn_labels, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f36fa5",
   "metadata": {},
   "source": [
    "Defining main function with calls of the dataset preparation and proper batching. Also calling CNN architechture, training, and optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fea026",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    emg_data_file = \"emg_gait_data.csv\"\n",
    "    ordered_channels = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "    trained_cnn = main(emg_data_file, ordered_channels)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
