{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suse2028/FE-NN-EMG-/blob/main/CNN_PINN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "de805878",
      "metadata": {
        "id": "de805878"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import scipy\n",
        "import scipy.signal as signal\n",
        "from scipy.signal import butter, lfilter\n",
        "from scipy.fft import fft, ifft, fftfreq\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import time\n",
        "import io\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34246727",
      "metadata": {
        "id": "34246727"
      },
      "source": [
        "Relevant importations: Preprocessing is mainly done with scipy, and ML is written using Pytorch. Dataset split is done with sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "4612e727",
      "metadata": {
        "id": "4612e727"
      },
      "outputs": [],
      "source": [
        "def download_data(save_dir = './data/SIAT-LLMD'):\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "    return save_dir\n",
        "\n",
        "download_data()\n",
        "\n",
        "def process_siat_llmd(data_dir, output_file='siat_llmd_processed.pkl'):\n",
        "    from scipy.io import loadmat\n",
        "\n",
        "    processed_data = []\n",
        "    emg_channels = ['LTA', 'LMG', 'LPL', 'LBF', 'LST', 'LVM', 'LVI', 'LRA', 'LFE']\n",
        "    joint_angle_cols = ['hip_flexion', 'knee_angle', 'ankle_angle']\n",
        "\n",
        "    for subject_dir in os.listdir(data_dir):\n",
        "        subject_path = os.path.join(data_dir, subject_dir)\n",
        "        if not os.path.isdir(subject_path):\n",
        "            continue\n",
        "\n",
        "        for trial_file in os.listdir(subject_path):\n",
        "            if not trial_file.endswith('.mat'):\n",
        "                continue\n",
        "\n",
        "            data = loadmat(os.path.join(subject_path, trial_file))\n",
        "\n",
        "\n",
        "            emg_raw = data['emg_data'][:, :9].T\n",
        "            emg_down = signal.resample(emg_raw, int(emg_raw.shape[1]/8), axis=1)\n",
        "\n",
        "            # Extract joint angles (100Hz) and interpolate to 125Hz\n",
        "            angles = data['joint_angles'][:, :3]  # (n_samples, 3)\n",
        "            angles_interp = signal.resample(angles, emg_down.shape[1], axis=0)\n",
        "\n",
        "            # Time alignment\n",
        "            processed_data.append({\n",
        "                'emg': emg_down,\n",
        "                'angles': angles_interp.T,  # (3, n_samples)\n",
        "                'subject': int(subject_dir.split('_')[-1]),\n",
        "                'movement': trial_file.split('_')[0]\n",
        "            })\n",
        "\n",
        "    # Save processed data\n",
        "    with open(output_file, 'wb') as f:\n",
        "        pickle.dump(processed_data, f)\n",
        "    return output_file\n",
        "\n",
        "def load_siat_llmd(file_path):\n",
        "\n",
        "    with open(file_path, 'rb') as f:\n",
        "      data = pickle.load(f)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    emg_signals = np.concatenate([d['emg'] for d in data], axis=1)\n",
        "    joint_angles = np.concatenate([d['angles'] for d in data], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "    return emg_signals, joint_angles"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7db4a6f",
      "metadata": {
        "id": "e7db4a6f"
      },
      "source": [
        "Dataset Used: UCI Dataset Lower Limb EMG. Takes EMG data of patients walking and applying force in different ways using during various leg movements.\n",
        "Key Characteristics:\n",
        "- 1. EMG readings are the relevant feature\n",
        "- 2. Label is (for the purposes of this model) a tuple: (angle, position) , angle relates to knee and ankle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8cacd56f",
      "metadata": {
        "id": "8cacd56f"
      },
      "outputs": [],
      "source": [
        "#Badnapss filter (restricted signal between 20-450 Hz, most of legitimate EMG signal)\n",
        "def bandpass_filter(signal_data, crit_freq=[20, 450], sampling_freq=125, plot=False, channel=0):\n",
        "    order = 4\n",
        "    b, a = scipy.signal.butter(order, crit_freq, btype='bandpass', fs=sampling_freq)\n",
        "    processed_signal = scipy.signal.filtfilt(b, a, signal_data)\n",
        "\n",
        "    if plot:\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.xlabel('Time')\n",
        "        plt.ylabel(f'Normalized amplitude of channel {channel}')\n",
        "        plt.title(f'{crit_freq[0]}-{crit_freq[1]}Hz bandpass filter')\n",
        "\n",
        "        signal_min = np.min(signal_data, axis=1, keepdims=True)\n",
        "        signal_max = np.max(signal_data, axis=1, keepdims=True)\n",
        "        normed_signal = (signal_data - signal_min) / (signal_max - signal_min)\n",
        "\n",
        "        filtered_min = np.min(processed_signal, axis=1, keepdims=True)\n",
        "        filtered_max = np.max(processed_signal, axis=1, keepdims=True)\n",
        "        normed_filt = (processed_signal - filtered_min) / (filtered_max - filtered_min)\n",
        "\n",
        "        plt.plot(np.arange(normed_signal[channel].size), normed_signal[channel], label='Input')\n",
        "        plt.plot(np.arange(normed_filt[channel].size), normed_filt[channel], label='Transformed')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    return processed_signal\n",
        "\n",
        "#Notch filter to eliminate common sources of artifacts from electronics (50-60 Hz)\n",
        "def notch_filter(signal_data, notch_freqs=[50, 60], Q=30, sampling_freq=125):\n",
        "    filtered_signal = signal_data.copy()\n",
        "\n",
        "    for f0 in notch_freqs:\n",
        "        b, a = signal.iirnotch(f0, Q, fs=sampling_freq)\n",
        "        filtered_signal = signal.filtfilt(b, a, filtered_signal)\n",
        "\n",
        "    return filtered_signal\n",
        "\n",
        "#Getting the absolute value of the data -> interest lies mainly in signal magnitude\n",
        "def rectify(signal_data):\n",
        "    return np.abs(signal_data)\n",
        "\n",
        "#FFT Filter: Given that any sharp signal deviation does not also occur periodically, eliminate it from the spectrum\n",
        "#Justification: We assume that the provided gait data is periodic,\n",
        "def fft_analysis_and_filter(signal_data, sampling_freq=125, gait_freq_range=[0.5, 2.5], plot=False, channel=0):\n",
        "    n_samples = signal_data.shape[1]\n",
        "    n_channels = signal_data.shape[0]\n",
        "\n",
        "    fft_result = fft(signal_data)\n",
        "    freqs = fftfreq(n_samples, 1 / sampling_freq)\n",
        "\n",
        "    mask = np.zeros((n_channels, n_samples), dtype=bool)\n",
        "    for i in range(n_channels):\n",
        "        mask[i] = (np.abs(freqs) < 0.1) | (\n",
        "                    (np.abs(freqs) >= gait_freq_range[0]) & (np.abs(freqs) <= gait_freq_range[1]))\n",
        "\n",
        "        for harmonic in range(2, 6):\n",
        "            mask[i] |= ((np.abs(freqs) >= harmonic * gait_freq_range[0]) &\n",
        "                        (np.abs(freqs) <= harmonic * gait_freq_range[1]))\n",
        "\n",
        "    filtered_fft = fft_result.copy()\n",
        "    for i in range(n_channels):\n",
        "        filtered_fft[i, ~mask[i]] = 0\n",
        "\n",
        "    filtered_signal = np.real(ifft(filtered_fft))\n",
        "\n",
        "    if plot and channel < n_channels:\n",
        "        plt.figure(figsize=(15, 10))\n",
        "\n",
        "        plt.subplot(3, 1, 1)\n",
        "        plt.title(f'Original EMG Signal - Channel {channel}')\n",
        "        plt.plot(signal_data[channel])\n",
        "        plt.xlabel('Sample')\n",
        "        plt.ylabel('Amplitude')\n",
        "\n",
        "        plt.subplot(3, 1, 2)\n",
        "        plt.title(f'Frequency Components - Channel {channel}')\n",
        "        pos_mask = freqs > 0\n",
        "        pos_freqs = freqs[pos_mask][:int(n_samples / 2)]\n",
        "        plt.plot(pos_freqs, 2.0 / n_samples * np.abs(fft_result[channel, pos_mask][:int(n_samples / 2)]))\n",
        "        plt.axvspan(gait_freq_range[0], gait_freq_range[1], alpha=0.3, color='green', label='Gait Freq Range')\n",
        "        plt.xlabel('Frequency (Hz)')\n",
        "        plt.ylabel('Magnitude')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(3, 1, 3)\n",
        "        plt.title(f'Filtered EMG Signal - Channel {channel}')\n",
        "        plt.plot(filtered_signal[channel])\n",
        "        plt.xlabel('Sample')\n",
        "        plt.ylabel('Amplitude')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    return filtered_signal"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "403642af",
      "metadata": {
        "id": "403642af"
      },
      "source": [
        "Preprocessing Methods:\n",
        "- 1. Bandpass Filter: Constrain EMG spectrum between 20-450 mV (<20 is too low to be induced by muscle activity and >450 is too high for any muscular activity)\n",
        "- 2. Notch Filter: Removes spectrum between 50-60 mV (common artifact from surrounding electronics)\n",
        "- 3. Rectification: Taking the absolute value gives us the magnitude of the spectrum, which is of more interest in establishing a boundary condition\n",
        "- 4. FFT Filter: Gait is inherently periodic, to an extent, therefore any spikes in the spectrum, given that they do not follow a periodic pattern, are unlikely to be a good feature. The FFT transform confirms the count of the deviant reading and then checks for its periodicity, which if confirmed False, eliminates it from the spectrum.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c8f9925c",
      "metadata": {
        "id": "c8f9925c"
      },
      "outputs": [],
      "source": [
        "def segmentation(signal_data, sampling_freq=125, window_size=1, window_shift=0.016):\n",
        "    w_size = int(sampling_freq * window_size)\n",
        "    w_shift = int(sampling_freq * window_shift)\n",
        "\n",
        "    segments = []\n",
        "    i = 0\n",
        "    while i + w_size <= signal_data.shape[1]:\n",
        "        segments.append(signal_data[:, i:i + w_size])\n",
        "        i += w_shift\n",
        "\n",
        "    return segments\n",
        "\n",
        "#is each segment a cycle of voluntary muscle contraction? -> solve\n",
        "def MVC_normalization(signal_data):\n",
        "    MVC = []\n",
        "    for i in segments:\n",
        "        entry = max(segments[i])\n",
        "        MVC += entry\n",
        "\n",
        "    processed_signal = (MVC)\n",
        "\n",
        "\n",
        "\n",
        "def channel_rearrangement(signal_data, channel_order):\n",
        "    channel_order = [channel - 1 for channel in channel_order]\n",
        "    reindexed = np.zeros_like(signal_data)\n",
        "    for i, ind in enumerate(channel_order):\n",
        "        reindexed[i] = signal_data[ind]\n",
        "    return reindexed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85ac8c5f",
      "metadata": {
        "id": "85ac8c5f"
      },
      "source": [
        "Divide up the proccessed spectrum into segments of pre-defined size, appending them to an initialized list to create an iterable for Pytorch's custom data batching in the future. Rearrange the channels according to how they are presented in the original dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7dfa01c7",
      "metadata": {
        "id": "7dfa01c7"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(file_path, ordered_channels, test_size=0.25):\n",
        "    emg_data, labels = load_siat_llmd(file_path)\n",
        "\n",
        "    if ordered_channels:\n",
        "        emg_data = channel_rearrangement(emg_data, ordered_channels)\n",
        "\n",
        "    filtered_emg = bandpass_filter(emg_data, [20, 450], 125)\n",
        "    notched_emg = notch_filter(filtered_emg, [50, 60], 30, 125)\n",
        "    rectified_emg = rectify(notched_emg)\n",
        "    clean_emg = fft_analysis_and_filter(rectified_emg, 125, [0.5, 2.5])\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        clean_emg.T,\n",
        "        labels,\n",
        "        test_size=test_size,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    X_val, X_test = X_test[:len(X_test) // 2], X_test[len(X_test) // 2:]\n",
        "    y_val, y_test = y_test[:len(y_test) // 2], y_test[len(y_test) // 2:]\n",
        "\n",
        "    X_train, X_val, X_test = X_train.T, X_val.T, X_test.T\n",
        "\n",
        "    train_emg = []\n",
        "    train_labels = []\n",
        "    valid_emg = []\n",
        "    valid_labels = []\n",
        "    test_emg = []\n",
        "    test_labels = []\n",
        "\n",
        "    train_segments = segmentation(X_train, 125, window_size=1.5, window_shift=0.0175)\n",
        "    train_emg.extend(train_segments)\n",
        "    train_labels.extend([y_train[0]] * len(train_segments))\n",
        "\n",
        "    val_segments = segmentation(X_val, 125, window_size=1.5, window_shift=0.0175)\n",
        "    valid_emg.extend(val_segments)\n",
        "    valid_labels.extend([y_val[0]] * len(val_segments))\n",
        "\n",
        "    test_segments = segmentation(X_test, 125, window_size=1.5, window_shift=0.0175)\n",
        "    test_emg.extend(test_segments)\n",
        "    test_labels.extend([y_test[0]] * len(test_segments))\n",
        "\n",
        "    return (\n",
        "        np.array(train_emg), np.array(train_labels),\n",
        "        np.array(valid_emg), np.array(valid_labels),\n",
        "        np.array(test_emg), np.array(test_labels)\n",
        "    )\n",
        "\n",
        "\n",
        "class EMGDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = torch.tensor(features, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.features[idx]\n",
        "        y = self.labels[idx]\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6eb0b842",
      "metadata": {
        "id": "6eb0b842"
      },
      "source": [
        "Create train-test splits in the dataset for future model refinement. Use Pytorch custom Dataset class to define features and labels as tensors, batching will be done in a __main__ function later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "767202ee",
      "metadata": {
        "id": "767202ee"
      },
      "outputs": [],
      "source": [
        "class CNNRegression(nn.Module):\n",
        "    def __init__(self, input_channels, seq_length):\n",
        "        super(CNNRegression, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=3, padding=1)\n",
        "        self.pool1 = nn.MaxPool1d(2)\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(64, 32, kernel_size=3, padding=1)\n",
        "        self.pool2 = nn.MaxPool1d(2)\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "\n",
        "        self.conv3 = nn.Conv1d(32, 16, kernel_size=3, padding=1)\n",
        "        self.pool3 = nn.MaxPool1d(2)\n",
        "        self.dropout3 = nn.Dropout(0.3)\n",
        "\n",
        "        self.flat_features = 16 * (seq_length // 8)\n",
        "\n",
        "        self.fc1 = nn.Linear(self.flat_features, 64)\n",
        "        self.dropout4 = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 2)\n",
        "\n",
        "    def forward(self, x, t=None):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool3(x)\n",
        "        x = self.dropout3(x)\n",
        "\n",
        "        x = x.view(-1, self.flat_features)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout4(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        output = self.fc3(x)\n",
        "\n",
        "        return output\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88381451",
      "metadata": {
        "id": "88381451"
      },
      "source": [
        "CNN Structure:\n",
        "- 1. Justification for CNN Use: Passing a convolution across the EMG spectrum can help recognize patterns, which when aided by periodicity, will help define a physically accurate boundary condition even further.\n",
        "- 2. Conv1D layers were used alongside MaxPool, Dropout, as well as manual feature reduction transform, followed by a Linear Layer at the end to flatten the transforms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8214a331",
      "metadata": {
        "id": "8214a331"
      },
      "outputs": [],
      "source": [
        "def physics_loss(pred, x, t, w=4.0, z=3.0):\n",
        "    dtheta_dt = torch.autograd.grad(\n",
        "        outputs=pred,\n",
        "        inputs=t,\n",
        "        grad_outputs=torch.ones_like(pred),\n",
        "        create_graph=True\n",
        "    )[0]\n",
        "\n",
        "    d2theta_dt2 = torch.autograd.grad(\n",
        "        outputs=dtheta_dt,\n",
        "        inputs=t,\n",
        "        grad_outputs=torch.ones_like(dtheta_dt),\n",
        "        create_graph=True\n",
        "    )[0]\n",
        "\n",
        "    residual = d2theta_dt2 + w * dtheta_dt + z * pred\n",
        "    phys_loss = torch.mean(residual ** 2)\n",
        "\n",
        "    return phys_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb136450",
      "metadata": {
        "id": "bb136450"
      },
      "source": [
        "This makes the model a true PINN (Physics-Informed Neural Network). Given that the region of interest regarding the ideal boundary conditions is the lower-limb joints (ankle, knee), we can use an ODE to model the physical constraints. One ODE in many other simulation based models (such as OpenSim)\n",
        "is damper-driven oscillation (represented in residual in the code). This will be incorporated into the loss function later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "68b0a1b1",
      "metadata": {
        "id": "68b0a1b1"
      },
      "outputs": [],
      "source": [
        "def train_cnn_model(model, train_loader, valid_loader, optimizer, num_epochs=100, device='cpu'):\n",
        "    print(\"Starting CNN model training...\")\n",
        "    model.to(device)\n",
        "\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        data_loss_total = 0.0\n",
        "        phys_loss_total = 0.0\n",
        "\n",
        "        for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
        "            x_batch = x_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            batch_size, channels, seq_len = x_batch.shape\n",
        "            dt = 0.001\n",
        "            t = torch.linspace(0, dt * (seq_len - 1), seq_len, device=device).view(1, -1, 1)\n",
        "            t = t.repeat(batch_size, 1, 1).requires_grad_(True)\n",
        "\n",
        "            x_batch.requires_grad_(True)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(x_batch, t)\n",
        "\n",
        "            data_loss = F.mse_loss(pred, y_batch)\n",
        "            phys_loss = physics_loss(pred, x_batch, t)\n",
        "            total_loss = data_loss + 0.1 * phys_loss\n",
        "\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += total_loss.item()\n",
        "            data_loss_total += data_loss.item()\n",
        "            phys_loss_total += phys_loss.item()\n",
        "\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(f\"  Batch {batch_idx}/{len(train_loader)}, \"\n",
        "                      f\"Loss: {total_loss.item():.4f}, \"\n",
        "                      f\"Data Loss: {data_loss.item():.4f}, \"\n",
        "                      f\"Physics Loss: {phys_loss.item():.4f}\")\n",
        "\n",
        "        model.eval()\n",
        "        valid_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for x_batch, y_batch in valid_loader:\n",
        "                x_batch = x_batch.to(device)\n",
        "                y_batch = y_batch.to(device)\n",
        "\n",
        "                pred = model(x_batch)\n",
        "                loss = F.mse_loss(pred, y_batch)\n",
        "                valid_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        avg_data_loss = data_loss_total / len(train_loader)\n",
        "        avg_phys_loss = phys_loss_total / len(train_loader)\n",
        "        avg_valid_loss = valid_loss / len(valid_loader)\n",
        "\n",
        "        train_losses.append(avg_train_loss)\n",
        "        valid_losses.append(avg_valid_loss)\n",
        "\n",
        "        epoch_time = time.time() - start_time\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs} completed in {epoch_time:.2f} seconds.\")\n",
        "        print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
        "        print(f\"  Data Loss: {avg_data_loss:.4f}\")\n",
        "        print(f\"  Physics Loss: {avg_phys_loss:.4f}\")\n",
        "        print(f\"  Validation Loss: {avg_valid_loss:.4f}\")\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.plot(valid_losses, label='Validation Loss')\n",
        "    plt.title('Loss Over Time')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "396a9357",
      "metadata": {
        "id": "396a9357"
      },
      "source": [
        "Model Training: Regular data loss between predictions and labels use Mean Square Error computation. Note that a regularization constant is added to the physics loss. This hyperparameter is adjustable and allows for change in the physical constraint's influence on the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8d658f58",
      "metadata": {
        "id": "8d658f58"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_loader, device='cpu', boundary_model=None, is_lstm=False):\n",
        "    print(\"Evaluating model on test data...\")\n",
        "    model.eval()\n",
        "    if boundary_model:\n",
        "        boundary_model.eval()\n",
        "\n",
        "    test_loss = 0.0\n",
        "    predictions = []\n",
        "    labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_batch, y_batch in test_loader:\n",
        "            x_batch = x_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            if is_lstm and boundary_model:\n",
        "                boundary_cond = boundary_model(x_batch)\n",
        "                pred = model(x_batch, boundary_cond)\n",
        "            else:\n",
        "                pred = model(x_batch)\n",
        "\n",
        "            loss = F.mse_loss(pred, y_batch)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            predictions.extend(pred.cpu().numpy())\n",
        "            labels.extend(y_batch.cpu().numpy())\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_loader)\n",
        "    print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
        "\n",
        "\n",
        "    predictions = np.array(predictions)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    if predictions.shape[1] == 2:\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.scatter(labels[:, 0], predictions[:, 0], alpha=0.5)\n",
        "        plt.plot([min(labels[:, 0]), max(labels[:, 0])], [min(labels[:, 0]), max(labels[:, 0])], 'r--')\n",
        "        plt.xlabel('Actual Angle')\n",
        "        plt.ylabel('Predicted Angle')\n",
        "        plt.title('Angle Predictions')\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.scatter(labels[:, 1], predictions[:, 1], alpha=0.5)\n",
        "        plt.plot([min(labels[:, 1]), max(labels[:, 1])], [min(labels[:, 1]), max(labels[:, 1])], 'r--')\n",
        "        plt.xlabel('Actual Position')\n",
        "        plt.ylabel('Predicted Position')\n",
        "        plt.title('Position Predictions')\n",
        "    else:\n",
        "        plt.scatter(labels, predictions, alpha=0.5)\n",
        "        plt.plot([min(labels), max(labels)], [min(labels), max(labels)], 'r--')\n",
        "        plt.xlabel('Actual Values')\n",
        "        plt.ylabel('Predicted Values')\n",
        "        plt.title('Predictions vs labels')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return avg_test_loss, predictions, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed7a3dd4",
      "metadata": {
        "id": "ed7a3dd4"
      },
      "source": [
        "Evaluate the model, returning loss averaged over the size of the dataset, and the predicted tuple and ground truth tuple (angle, position)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "cff62d58",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "cff62d58",
        "outputId": "81e2a231-8e3c-41ce-eaac-4363c3a4608f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'emg_gait_data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-f6bfc5af66fe>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0memg_data_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"emg_gait_data.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mordered_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mtrained_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memg_data_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordered_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-f6bfc5af66fe>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(emg_data_file, ordered_channels)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Using device: {device}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     train_emg, train_labels, valid_emg, valid_labels, test_emg, test_labels = prepare_dataset(\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0memg_data_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordered_channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     )\n",
            "\u001b[0;32m<ipython-input-18-c444231178c9>\u001b[0m in \u001b[0;36mprepare_dataset\u001b[0;34m(file_path, ordered_channels, test_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepare_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordered_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0memg_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_siat_llmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mordered_channels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0memg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchannel_rearrangement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memg_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordered_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-82759d369f09>\u001b[0m in \u001b[0;36mload_siat_llmd\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_siat_llmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'emg_gait_data.csv'"
          ]
        }
      ],
      "source": [
        "def main(emg_data_file, ordered_channels=None):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    train_emg, train_labels, valid_emg, valid_labels, test_emg, test_labels = prepare_dataset(\n",
        "        emg_data_file, ordered_channels\n",
        "    )\n",
        "\n",
        "    input_channels = train_emg.shape[1]\n",
        "    seq_length = train_emg.shape[2]\n",
        "\n",
        "    train_dataset = EMGDataset(train_emg, train_labels)\n",
        "    valid_dataset = EMGDataset(valid_emg, valid_labels)\n",
        "    test_dataset = EMGDataset(test_emg, test_labels)\n",
        "\n",
        "    batch_size = 32\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    cnn_model = CNNRegression(input_channels, seq_length).to(device)\n",
        "    cnn_optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
        "\n",
        "    trained_cnn = train_cnn_model(\n",
        "        cnn_model,\n",
        "        train_loader,\n",
        "        valid_loader,\n",
        "        cnn_optimizer,\n",
        "        num_epochs=50,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    cnn_test_loss, cnn_predictions, cnn_labels = evaluate_model(\n",
        "        trained_cnn,\n",
        "        test_loader,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    torch.save(trained_cnn.state_dict(), 'cnn_boundary_model.pth')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    emg_data_file = \"emg_gait_data.csv\"\n",
        "    ordered_channels = [1, 2, 3, 4, 5, 6, 7, 8]\n",
        "    trained_cnn = main(emg_data_file, ordered_channels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a70312e",
      "metadata": {
        "id": "4a70312e"
      },
      "source": [
        "Define main function to batch the preprocessed data, and define an object of the CNN followed by its training and evaluation. Execute main function."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}