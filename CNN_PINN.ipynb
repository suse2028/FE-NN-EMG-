{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suse2028/FE-NN-EMG-/blob/main/CNN_PINN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "de805878",
      "metadata": {
        "id": "de805878"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import scipy\n",
        "import scipy.signal as signal\n",
        "from scipy.signal import butter, lfilter\n",
        "from scipy.fft import fft, ifft, fftfreq\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import time\n",
        "import io\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34246727",
      "metadata": {
        "id": "34246727"
      },
      "source": [
        "Relevant importations: Preprocessing is mainly done with scipy, and ML is written using Pytorch. Dataset split is done with sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "4612e727",
      "metadata": {
        "id": "4612e727"
      },
      "outputs": [],
      "source": [
        "def load_txt_files(file_paths):\n",
        "    \"\"\"Load EMG data from multiple .txt log files\"\"\"\n",
        "    emg_data_list = []\n",
        "    joint_angles_list = []\n",
        "\n",
        "    for file_path in file_paths:\n",
        "        try:\n",
        "            with open(file_path, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "\n",
        "            emg_channels = []\n",
        "            angles = []\n",
        "\n",
        "            for line in lines:\n",
        "                if line.strip() and not line.startswith('#'):\\\n",
        "                  values = [float(val) for val in line.strip().split(',')]\n",
        "                if len(values) >= 12:\n",
        "                        emg_channels.append(values[:9])  # First 9 values are EMG\n",
        "                        angles.append(values[9:12])  # Next 3 values are joint angles\n",
        "\n",
        "            if emg_channels and angles:\n",
        "                # Convert to numpy arrays and transpose to get (channels, samples)\n",
        "                emg_data = np.array(emg_channels).T\n",
        "                joint_angles = np.array(angles).T\n",
        "\n",
        "                emg_data_list.append(emg_data)\n",
        "                joint_angles_list.append(joint_angles)\n",
        "                print(f\"Successfully loaded data from {file_path}\")\n",
        "            else:\n",
        "                print(f\"No valid data found in {file_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {file_path}: {e}\")\n",
        "\n",
        "    if not emg_data_list:\n",
        "        raise ValueError(\"No data could be loaded from the provided files\")\n",
        "\n",
        "    # Concatenate data from all files\n",
        "    all_emg = np.concatenate(emg_data_list, axis=1)\n",
        "    all_angles = np.concatenate(joint_angles_list, axis=1)\n",
        "\n",
        "    return all_emg, all_angles\n",
        "\n",
        "def find_log_files(directory='.'):\n",
        "    \"\"\"Find all .log files in the specified directory\"\"\"\n",
        "    log_files = [f for f in os.listdir(directory) if f.endswith('.log')]\n",
        "    return [os.path.join(directory, f) for f in log_files]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7db4a6f",
      "metadata": {
        "id": "e7db4a6f"
      },
      "source": [
        "Dataset Used: UCI Dataset Lower Limb EMG. Takes EMG data of patients walking and applying force in different ways using during various leg movements.\n",
        "Key Characteristics:\n",
        "- 1. EMG readings are the relevant feature\n",
        "- 2. Label is (for the purposes of this model) a tuple: (angle, position) , angle relates to knee and ankle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8cacd56f",
      "metadata": {
        "id": "8cacd56f"
      },
      "outputs": [],
      "source": [
        "#Badnapss filter (restricted signal between 20-450 Hz, most of legitimate EMG signal)\n",
        "def bandpass_filter(signal_data, crit_freq=[20, 450], sampling_freq=125, plot=False, channel=0):\n",
        "    order = 4\n",
        "    b, a = scipy.signal.butter(order, crit_freq, btype='bandpass', fs=sampling_freq)\n",
        "    processed_signal = scipy.signal.filtfilt(b, a, signal_data)\n",
        "\n",
        "    if plot:\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.xlabel('Time')\n",
        "        plt.ylabel(f'Normalized amplitude of channel {channel}')\n",
        "        plt.title(f'{crit_freq[0]}-{crit_freq[1]}Hz bandpass filter')\n",
        "\n",
        "        signal_min = np.min(signal_data, axis=1, keepdims=True)\n",
        "        signal_max = np.max(signal_data, axis=1, keepdims=True)\n",
        "        normed_signal = (signal_data - signal_min) / (signal_max - signal_min)\n",
        "\n",
        "        filtered_min = np.min(processed_signal, axis=1, keepdims=True)\n",
        "        filtered_max = np.max(processed_signal, axis=1, keepdims=True)\n",
        "        normed_filt = (processed_signal - filtered_min) / (filtered_max - filtered_min)\n",
        "\n",
        "        plt.plot(np.arange(normed_signal[channel].size), normed_signal[channel], label='Input')\n",
        "        plt.plot(np.arange(normed_filt[channel].size), normed_filt[channel], label='Transformed')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    return processed_signal\n",
        "\n",
        "#Notch filter to eliminate common sources of artifacts from electronics (50-60 Hz)\n",
        "def notch_filter(signal_data, notch_freqs=[50, 60], Q=30, sampling_freq=125):\n",
        "    filtered_signal = signal_data.copy()\n",
        "\n",
        "    for f0 in notch_freqs:\n",
        "        b, a = signal.iirnotch(f0, Q, fs=sampling_freq)\n",
        "        filtered_signal = signal.filtfilt(b, a, filtered_signal)\n",
        "\n",
        "    return filtered_signal\n",
        "\n",
        "#Getting the absolute value of the data -> interest lies mainly in signal magnitude\n",
        "def rectify(signal_data):\n",
        "    return np.abs(signal_data)\n",
        "\n",
        "#FFT Filter: Given that any sharp signal deviation does not also occur periodically, eliminate it from the spectrum\n",
        "#Justification: We assume that the provided gait data is periodic,\n",
        "def fft_analysis_and_filter(signal_data, sampling_freq=125, gait_freq_range=[0.5, 2.5], plot=False, channel=0):\n",
        "    n_samples = signal_data.shape[1]\n",
        "    n_channels = signal_data.shape[0]\n",
        "\n",
        "    fft_result = fft(signal_data)\n",
        "    freqs = fftfreq(n_samples, 1 / sampling_freq)\n",
        "\n",
        "    mask = np.zeros((n_channels, n_samples), dtype=bool)\n",
        "    for i in range(n_channels):\n",
        "        mask[i] = (np.abs(freqs) < 0.1) | (\n",
        "                    (np.abs(freqs) >= gait_freq_range[0]) & (np.abs(freqs) <= gait_freq_range[1]))\n",
        "\n",
        "        for harmonic in range(2, 6):\n",
        "            mask[i] |= ((np.abs(freqs) >= harmonic * gait_freq_range[0]) &\n",
        "                        (np.abs(freqs) <= harmonic * gait_freq_range[1]))\n",
        "\n",
        "    filtered_fft = fft_result.copy()\n",
        "    for i in range(n_channels):\n",
        "        filtered_fft[i, ~mask[i]] = 0\n",
        "\n",
        "    filtered_signal = np.real(ifft(filtered_fft))\n",
        "\n",
        "    if plot and channel < n_channels:\n",
        "        plt.figure(figsize=(15, 10))\n",
        "\n",
        "        plt.subplot(3, 1, 1)\n",
        "        plt.title(f'Original EMG Signal - Channel {channel}')\n",
        "        plt.plot(signal_data[channel])\n",
        "        plt.xlabel('Sample')\n",
        "        plt.ylabel('Amplitude')\n",
        "\n",
        "        plt.subplot(3, 1, 2)\n",
        "        plt.title(f'Frequency Components - Channel {channel}')\n",
        "        pos_mask = freqs > 0\n",
        "        pos_freqs = freqs[pos_mask][:int(n_samples / 2)]\n",
        "        plt.plot(pos_freqs, 2.0 / n_samples * np.abs(fft_result[channel, pos_mask][:int(n_samples / 2)]))\n",
        "        plt.axvspan(gait_freq_range[0], gait_freq_range[1], alpha=0.3, color='green', label='Gait Freq Range')\n",
        "        plt.xlabel('Frequency (Hz)')\n",
        "        plt.ylabel('Magnitude')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(3, 1, 3)\n",
        "        plt.title(f'Filtered EMG Signal - Channel {channel}')\n",
        "        plt.plot(filtered_signal[channel])\n",
        "        plt.xlabel('Sample')\n",
        "        plt.ylabel('Amplitude')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    return filtered_signal"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "403642af",
      "metadata": {
        "id": "403642af"
      },
      "source": [
        "Preprocessing Methods:\n",
        "- 1. Bandpass Filter: Constrain EMG spectrum between 20-450 mV (<20 is too low to be induced by muscle activity and >450 is too high for any muscular activity)\n",
        "- 2. Notch Filter: Removes spectrum between 50-60 mV (common artifact from surrounding electronics)\n",
        "- 3. Rectification: Taking the absolute value gives us the magnitude of the spectrum, which is of more interest in establishing a boundary condition\n",
        "- 4. FFT Filter: Gait is inherently periodic, to an extent, therefore any spikes in the spectrum, given that they do not follow a periodic pattern, are unlikely to be a good feature. The FFT transform confirms the count of the deviant reading and then checks for its periodicity, which if confirmed False, eliminates it from the spectrum.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c8f9925c",
      "metadata": {
        "id": "c8f9925c"
      },
      "outputs": [],
      "source": [
        "def segmentation(signal_data, sampling_freq=125, window_size=1, window_shift=0.016):\n",
        "    w_size = int(sampling_freq * window_size)\n",
        "    w_shift = int(sampling_freq * window_shift)\n",
        "\n",
        "    segments = []\n",
        "    i = 0\n",
        "    while i + w_size <= signal_data.shape[1]:\n",
        "        segments.append(signal_data[:, i:i + w_size])\n",
        "        i += w_shift\n",
        "\n",
        "    return segments\n",
        "\n",
        "def channel_rearrangement(signal_data, channel_order):\n",
        "    channel_order = [channel - 1 for channel in channel_order]\n",
        "    reindexed = np.zeros_like(signal_data)\n",
        "    for i, ind in enumerate(channel_order):\n",
        "        reindexed[i] = signal_data[ind]\n",
        "    return reindexed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85ac8c5f",
      "metadata": {
        "id": "85ac8c5f"
      },
      "source": [
        "Divide up the proccessed spectrum into segments of pre-defined size, appending them to an initialized list to create an iterable for Pytorch's custom data batching in the future. Rearrange the channels according to how they are presented in the original dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7dfa01c7",
      "metadata": {
        "id": "7dfa01c7"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(file_path, ordered_channels, test_size=0.25):\n",
        "    emg_data, labels = load_txt_files(file_paths)\n",
        "\n",
        "    if ordered_channels:\n",
        "        emg_data = channel_rearrangement(emg_data, ordered_channels)\n",
        "\n",
        "    filtered_emg = bandpass_filter(emg_data, [20, 450], 125)\n",
        "    notched_emg = notch_filter(filtered_emg, [50, 60], 30, 125)\n",
        "    rectified_emg = rectify(notched_emg)\n",
        "    clean_emg = fft_analysis_and_filter(rectified_emg, 125, [0.5, 2.5])\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        clean_emg.T,\n",
        "        labels,\n",
        "        test_size=test_size,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    X_val, X_test = X_test[:len(X_test) // 2], X_test[len(X_test) // 2:]\n",
        "    y_val, y_test = y_test[:len(y_test) // 2], y_test[len(y_test) // 2:]\n",
        "\n",
        "    X_train, X_val, X_test = X_train.T, X_val.T, X_test.T\n",
        "\n",
        "    train_emg = []\n",
        "    train_labels = []\n",
        "    valid_emg = []\n",
        "    valid_labels = []\n",
        "    test_emg = []\n",
        "    test_labels = []\n",
        "\n",
        "    train_segments = segmentation(X_train, 125, window_size=1.5, window_shift=0.0175)\n",
        "    train_emg.extend(train_segments)\n",
        "    train_labels.extend([y_train[0]] * len(train_segments))\n",
        "\n",
        "    val_segments = segmentation(X_val, 125, window_size=1.5, window_shift=0.0175)\n",
        "    valid_emg.extend(val_segments)\n",
        "    valid_labels.extend([y_val[0]] * len(val_segments))\n",
        "\n",
        "    test_segments = segmentation(X_test, 125, window_size=1.5, window_shift=0.0175)\n",
        "    test_emg.extend(test_segments)\n",
        "    test_labels.extend([y_test[0]] * len(test_segments))\n",
        "\n",
        "    return (\n",
        "        np.array(train_emg), np.array(train_labels),\n",
        "        np.array(valid_emg), np.array(valid_labels),\n",
        "        np.array(test_emg), np.array(test_labels)\n",
        "    )\n",
        "\n",
        "\n",
        "class EMGDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = torch.tensor(features, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.features[idx]\n",
        "        y = self.labels[idx]\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6eb0b842",
      "metadata": {
        "id": "6eb0b842"
      },
      "source": [
        "Create train-test splits in the dataset for future model refinement. Use Pytorch custom Dataset class to define features and labels as tensors, batching will be done in a __main__ function later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "767202ee",
      "metadata": {
        "id": "767202ee"
      },
      "outputs": [],
      "source": [
        "class CNNRegression(nn.Module):\n",
        "    def __init__(self, input_channels, seq_length):\n",
        "        super(CNNRegression, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=3, padding=1)\n",
        "        self.pool1 = nn.MaxPool1d(2)\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(64, 32, kernel_size=3, padding=1)\n",
        "        self.pool2 = nn.MaxPool1d(2)\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "\n",
        "        self.conv3 = nn.Conv1d(32, 16, kernel_size=3, padding=1)\n",
        "        self.pool3 = nn.MaxPool1d(2)\n",
        "        self.dropout3 = nn.Dropout(0.3)\n",
        "\n",
        "        self.flat_features = 16 * (seq_length // 8)\n",
        "\n",
        "        self.fc1 = nn.Linear(self.flat_features, 64)\n",
        "        self.dropout4 = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 2)\n",
        "\n",
        "    def forward(self, x, t=None):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool3(x)\n",
        "        x = self.dropout3(x)\n",
        "\n",
        "        x = x.view(-1, self.flat_features)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout4(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        output = self.fc3(x)\n",
        "\n",
        "        return output\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88381451",
      "metadata": {
        "id": "88381451"
      },
      "source": [
        "CNN Structure:\n",
        "- 1. Justification for CNN Use: Passing a convolution across the EMG spectrum can help recognize patterns, which when aided by periodicity, will help define a physically accurate boundary condition even further.\n",
        "- 2. Conv1D layers were used alongside MaxPool, Dropout, as well as manual feature reduction transform, followed by a Linear Layer at the end to flatten the transforms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8214a331",
      "metadata": {
        "id": "8214a331"
      },
      "outputs": [],
      "source": [
        "def physics_loss(pred, x, t, w=4.0, z=3.0):\n",
        "    dtheta_dt = torch.autograd.grad(\n",
        "        outputs=pred,\n",
        "        inputs=t,\n",
        "        grad_outputs=torch.ones_like(pred),\n",
        "        create_graph=True\n",
        "    )[0]\n",
        "\n",
        "    d2theta_dt2 = torch.autograd.grad(\n",
        "        outputs=dtheta_dt,\n",
        "        inputs=t,\n",
        "        grad_outputs=torch.ones_like(dtheta_dt),\n",
        "        create_graph=True\n",
        "    )[0]\n",
        "\n",
        "    residual = d2theta_dt2 + w * dtheta_dt + z * pred\n",
        "    phys_loss = torch.mean(residual ** 2)\n",
        "\n",
        "    return phys_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb136450",
      "metadata": {
        "id": "bb136450"
      },
      "source": [
        "This makes the model a true PINN (Physics-Informed Neural Network). Given that the region of interest regarding the ideal boundary conditions is the lower-limb joints (ankle, knee), we can use an ODE to model the physical constraints. One ODE in many other simulation based models (such as OpenSim)\n",
        "is damper-driven oscillation (represented in residual in the code). This will be incorporated into the loss function later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "68b0a1b1",
      "metadata": {
        "id": "68b0a1b1"
      },
      "outputs": [],
      "source": [
        "def train_cnn_model(model, train_loader, valid_loader, optimizer, num_epochs=100, device='cpu'):\n",
        "    print(\"Starting CNN model training...\")\n",
        "    model.to(device)\n",
        "\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        data_loss_total = 0.0\n",
        "        phys_loss_total = 0.0\n",
        "\n",
        "        for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
        "            x_batch = x_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            batch_size, channels, seq_len = x_batch.shape\n",
        "            dt = 0.001\n",
        "            t = torch.linspace(0, dt * (seq_len - 1), seq_len, device=device).view(1, -1, 1)\n",
        "            t = t.repeat(batch_size, 1, 1).requires_grad_(True)\n",
        "\n",
        "            x_batch.requires_grad_(True)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(x_batch, t)\n",
        "\n",
        "            data_loss = F.mse_loss(pred, y_batch)\n",
        "            phys_loss = physics_loss(pred, x_batch, t)\n",
        "            total_loss = data_loss + 0.1 * phys_loss\n",
        "\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += total_loss.item()\n",
        "            data_loss_total += data_loss.item()\n",
        "            phys_loss_total += phys_loss.item()\n",
        "\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(f\"  Batch {batch_idx}/{len(train_loader)}, \"\n",
        "                      f\"Loss: {total_loss.item():.4f}, \"\n",
        "                      f\"Data Loss: {data_loss.item():.4f}, \"\n",
        "                      f\"Physics Loss: {phys_loss.item():.4f}\")\n",
        "\n",
        "        model.eval()\n",
        "        valid_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for x_batch, y_batch in valid_loader:\n",
        "                x_batch = x_batch.to(device)\n",
        "                y_batch = y_batch.to(device)\n",
        "\n",
        "                pred = model(x_batch)\n",
        "                loss = F.mse_loss(pred, y_batch)\n",
        "                valid_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        avg_data_loss = data_loss_total / len(train_loader)\n",
        "        avg_phys_loss = phys_loss_total / len(train_loader)\n",
        "        avg_valid_loss = valid_loss / len(valid_loader)\n",
        "\n",
        "        train_losses.append(avg_train_loss)\n",
        "        valid_losses.append(avg_valid_loss)\n",
        "\n",
        "        epoch_time = time.time() - start_time\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs} completed in {epoch_time:.2f} seconds.\")\n",
        "        print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
        "        print(f\"  Data Loss: {avg_data_loss:.4f}\")\n",
        "        print(f\"  Physics Loss: {avg_phys_loss:.4f}\")\n",
        "        print(f\"  Validation Loss: {avg_valid_loss:.4f}\")\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.plot(valid_losses, label='Validation Loss')\n",
        "    plt.title('Loss Over Time')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "396a9357",
      "metadata": {
        "id": "396a9357"
      },
      "source": [
        "Model Training: Regular data loss between predictions and labels use Mean Square Error computation. Note that a regularization constant is added to the physics loss. This hyperparameter is adjustable and allows for change in the physical constraint's influence on the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8d658f58",
      "metadata": {
        "id": "8d658f58"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_loader, device='cpu', boundary_model=None, is_lstm=False):\n",
        "    print(\"Evaluating model on test data...\")\n",
        "    model.eval()\n",
        "    if boundary_model:\n",
        "        boundary_model.eval()\n",
        "\n",
        "    test_loss = 0.0\n",
        "    predictions = []\n",
        "    labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_batch, y_batch in test_loader:\n",
        "            x_batch = x_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            if is_lstm and boundary_model:\n",
        "                boundary_cond = boundary_model(x_batch)\n",
        "                pred = model(x_batch, boundary_cond)\n",
        "            else:\n",
        "                pred = model(x_batch)\n",
        "\n",
        "            loss = F.mse_loss(pred, y_batch)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            predictions.extend(pred.cpu().numpy())\n",
        "            labels.extend(y_batch.cpu().numpy())\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_loader)\n",
        "    print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
        "\n",
        "\n",
        "    predictions = np.array(predictions)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    if predictions.shape[1] == 2:\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.scatter(labels[:, 0], predictions[:, 0], alpha=0.5)\n",
        "        plt.plot([min(labels[:, 0]), max(labels[:, 0])], [min(labels[:, 0]), max(labels[:, 0])], 'r--')\n",
        "        plt.xlabel('Actual Angle')\n",
        "        plt.ylabel('Predicted Angle')\n",
        "        plt.title('Angle Predictions')\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.scatter(labels[:, 1], predictions[:, 1], alpha=0.5)\n",
        "        plt.plot([min(labels[:, 1]), max(labels[:, 1])], [min(labels[:, 1]), max(labels[:, 1])], 'r--')\n",
        "        plt.xlabel('Actual Position')\n",
        "        plt.ylabel('Predicted Position')\n",
        "        plt.title('Position Predictions')\n",
        "    else:\n",
        "        plt.scatter(labels, predictions, alpha=0.5)\n",
        "        plt.plot([min(labels), max(labels)], [min(labels), max(labels)], 'r--')\n",
        "        plt.xlabel('Actual Values')\n",
        "        plt.ylabel('Predicted Values')\n",
        "        plt.title('Predictions vs labels')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return avg_test_loss, predictions, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed7a3dd4",
      "metadata": {
        "id": "ed7a3dd4"
      },
      "source": [
        "Evaluate the model, returning loss averaged over the size of the dataset, and the predicted tuple and ground truth tuple (angle, position)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a70312e",
      "metadata": {
        "id": "4a70312e"
      },
      "source": [
        "Define main function to batch the preprocessed data, and define an object of the CNN followed by its training and evaluation. Execute main function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "cff62d58",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "cff62d58",
        "outputId": "ee261d87-80f4-45c7-cee3-866015fa2c56"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-42-6c2f3182c8e1>, line 15)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-42-6c2f3182c8e1>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    , ordered_channels\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "def main(emg_data_file, ordered_channels=None):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    log_files = find_log_files()\n",
        "    if not log_files:\n",
        "        print(\"No log files found. Generating synthetic data instead.\")\n",
        "        # Generate synthetic data as a fallback\n",
        "        emg_data = np.random.randn(9, 5000) * 0.1\n",
        "        joint_angles = np.random.randn(3, 5000) * 10\n",
        "    else:\n",
        "        print(f\"Found {len(log_files)} log files: {log_files}\")\n",
        "        # Load data from log files\n",
        "        emg_data, joint_angles = load_txt_files(log_files)\n",
        "\n",
        "    train_emg, train_labels, valid_emg, valid_labels, test_emg, test_labels = prepare_dataset(\n",
        "        , ordered_channels\n",
        "    )\n",
        "    input_channels = train_emg.shape[1]\n",
        "    seq_length = train_emg.shape[2]\n",
        "\n",
        "    train_dataset = EMGDataset(train_emg, train_labels)\n",
        "    valid_dataset = EMGDataset(valid_emg, valid_labels)\n",
        "    test_dataset = EMGDataset(test_emg, test_labels)\n",
        "\n",
        "    batch_size = 32\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    cnn_model = CNNRegression(input_channels, seq_length).to(device)\n",
        "    cnn_optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
        "\n",
        "    trained_cnn = train_cnn_model(\n",
        "        cnn_model,\n",
        "        train_loader,\n",
        "        valid_loader,\n",
        "        cnn_optimizer,\n",
        "        num_epochs=50,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    cnn_test_loss, cnn_predictions, cnn_labels = evaluate_model(\n",
        "        trained_cnn,\n",
        "        test_loader,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    torch.save(trained_cnn.state_dict(), 'cnn_boundary_model.pth')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    trained_cnn = main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "log_files = [f for f in os.listdir() if f.endswith('.log')]\n",
        "print(f\"Found {len(log_files)} log files: {log_files}\")\n",
        "\n",
        "# Now you can pass this list to your function\n",
        "emg_data, joint_angles = load_txt_files(log_files)"
      ],
      "metadata": {
        "id": "pIudq-SZyZsP",
        "outputId": "ca307d57-a132-400d-f5b4-0ffcb05a60d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "id": "pIudq-SZyZsP",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 log files: []\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No data could be loaded from the provided files",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-68656011cd59>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Now you can pass this list to your function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0memg_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoint_angles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_txt_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-40-7000a0ed3b7e>\u001b[0m in \u001b[0;36mload_txt_files\u001b[0;34m(file_paths)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0memg_data_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No data could be loaded from the provided files\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# Concatenate data from all files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No data could be loaded from the provided files"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}